{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 : Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Introduction\n",
    "\n",
    "L'objectif de ce premier TP est d'étudier les methodes d'ensemble, en particulier le Boosting.\n",
    "Il sera à réaliser en python 3. Les librairies utilisées sont installées sur les machines de l'université et de l'Ensicaen, vous pouvez néanmoins les installer sur vos propres machines à l'aide de l'utilitaire pip présent par défaut avec python.\n",
    "\t\n",
    "N'hésitez pas à regarder régulièrement la documentation de ces librairies, des exemples d'utilisation accompagnent généralement l'explication de chaque fonction.\n",
    "\n",
    "\n",
    "Langage utilisé:\n",
    "- Python 3: https://docs.python.org/3/\n",
    "\n",
    "Librairie de math:\n",
    "- Numpy: https://docs.scipy.org/doc/numpy/reference/\n",
    "- Scipy: https://docs.scipy.org/doc/scipy/reference/\n",
    "\n",
    "Librairie d'affichage de données:\n",
    "- Matplotilb: https://matplotlib.org/contents.html\n",
    "\n",
    "Librairie de traitement d'image:\n",
    "- Scikit-image: https://scikit-image.org/\n",
    "\n",
    "Librairie d'apprentissage automatique:\n",
    "- Scikit-learn: http://scikit-learn.org\n",
    "\n",
    "**Afin d'avoir un code optimisé, vous éviterez d'utiliser les instructions python3 `if`, `for` et `while` (sauf mention contraire dans le sujet).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import load_diabetes, make_circles\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Récupération des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous  allons  travailler  sur  des  données  d’apprentissage  réparties  en  deux  classes. Ces données sont issu de la base `iris`, disponible directement depuis `scikit learn`. \n",
    "\n",
    "Chaque exemple est composé des 4 caractéristiques suivantes:\n",
    "\n",
    "1. Sepal length en cm\n",
    "2. Sepal width en cm\n",
    "3. Petal length in cm\n",
    "4. Petal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la fonction `train_test_split` de `scikit-learn` ( https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html ) découpez les données en deux ensembles (*train* et *val*) de sorte à ce que 80% des données soit dans *train* et 20% dans test. \n",
    "Vous nommerez les données `X_train` et `X_test` et les labels `y_train` et `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant un objet de la classe `StandardScaler` de scikit-learn ( https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html ) normalisez les données de manière à avoir la moyenne à 0 et l’écart-type à 1. Vous placerez le résultat dans les variables `X_train_` et `X_test_`.\n",
    "\n",
    "L’opérateur précédent applique la transformation suivante: $z = \\dfrac{x -  \\mu}{\\sigma}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Boosting à l'aide de Scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utiliserons dans cette partie les fonctions de la librairie `scikit-learn` pour implémenter des méthodes de Boosting, en particulier AdaBoost.\n",
    "\n",
    "Nous étudierons dans cette partie les différents éléments important du Boosting à savoir:\n",
    "- le choix du modèle de base.\n",
    "- le nombre de modèle de base.\n",
    "\n",
    "Pour plus d'information sur l'utilisation d'AdaBoost dans `scikit-learn`, vous pouvez vous référer à la documentation : https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - AdaBoost par défaut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vous basant sur la documentation ( https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html ), apprenez un AdaBoost avec `2` comme `nombre d'estimateur` et un `DecisionTreeClassifier` d'une profondeur maximum de `1` comme `estimateur de base` sur les données d'apprentissage normalisées `X_train_`, que vous nommerez `clf_boost`. Vous mettrez à 'SAMME' le paramètre `algorithm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce bloc permet de valider votre code. Vous ne devez pas le modifier.  \n",
    "try:\n",
    "    np.testing.assert_equal(type(clf_boost),skl.ensemble._weight_boosting.AdaBoostClassifier,err_msg=\"\\033[93m {}\\033[00m\" .format('Test 1 : Le type de clf_boost est incorrect.'))\n",
    "    np.testing.assert_equal(type(clf_boost.base_estimator_),skl.tree._classes.DecisionTreeClassifier,err_msg=\"\\033[93m {}\\033[00m\" .format('Test 2 : Le type de base_estimator est incorrect.'))\n",
    "    try:\n",
    "        assert 'estimator_weights_' in clf_boost.__dict__\n",
    "    except Exception as e:\n",
    "        raise AssertionError(\"\\033[93m {}\\033[00m\" .format('Test 3 : Vous n\\'avez pas appris clf_boost.'))\n",
    "except Exception as e: \n",
    "    print(\"\\033[91m {}\\033[00m\" .format('KO - Au moins un test n\\'est pas validé')) \n",
    "    print('Information sur le test non valide:')\n",
    "    print(e)\n",
    "    raise e\n",
    "else:\n",
    "    print(\"\\033[92m {}\\033[00m\" .format('Ok - Tous les tests sont validés.')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la fonction `classification_report` ( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html ) de `scikit_learn`, affichez les performances du classifieurs sur la base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À votre avis, cette première utilisation d’Adaboost est-elle performante ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 La validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de paramètres à explorer est potentiellement important et il n'est pas toujours évident de connaiter les meilleurs combinaisons à utiliser pour un problème donné. `Scikit-learrn` met à disposition plusieurs solution pour explorer les paramètres possibles et calculer les performances finales. Vous retrouverez ces information à l'adresse: https://scikit-learn.org/stable/model_selection.html .\n",
    "Nous allons dans cette partie, nous concentrer plus particulièrement sur la validation croisée: https://scikit-learn.org/stable/modules/cross_validation.html .\n",
    "Commencez par lire en détail la documentation.\n",
    "\n",
    "À l'aide de la classe `GridSearchCV` https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html , trouvez les meilleurs paramètres parmi les configurations suivantes pour une fonction de coût de type `accuracy`:\n",
    "- Nombre estimateur entre [$1,20$].\n",
    "- Base estimateur doit être soit un `perceptron` ou un `arbre de décision`.\n",
    "- Dans le cas d'un `arbre de décision` vous ferez varier la profondeur maximum de l'arbre entre 1 et 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()\n",
    "estimator__max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Application d'une PCA sur les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de pouvoir visualiser les données vous devez appliquer une réduction de la dimensionnalité, pour cela nous allons appliquer une `PCA` sur les données `X_train_`. En vous basant sur la documentation (https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html), apprenez une `PCA` avec 2 composantes conservées sur `X_train_` ensuite transformez `X_train_` et `X_train_` en `X_train_pca` `X_test_pca` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprendre le même classifieur (2 estimateurs, `DecisionTreeClassifier` de profondeur 1) que précédemment sur `X_train_pca`, vous l'appelerez `clf_boost_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la fonction `classification_report` ( https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html ) de `scikit_learn`, affichez les performances du classifieurs sur la base de `X_test_pca`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que pouvez-vous dire des performances ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Influence du nombre d'estimateur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vous donnons le code suivant permettant de visualiser les performances du classifieur `clf` sur les données du TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_boundary(clf, X_train, X_test, y_train, y_test,n_estimators, sample_weight=1):\n",
    "    cm_bright = ListedColormap([\"#FF0000\", \"#0000FF\"]) if len(np.unique(y_train))==2 else ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"]) \n",
    "    disp = DecisionBoundaryDisplay.from_estimator(clf, X_train, cmap=cm_bright, alpha=0.3, eps=0.5)\n",
    "    disp.figure_.set_figheight(12)\n",
    "    disp.figure_.set_figwidth(20)\n",
    "    disp.ax_.scatter(X_train[:,0], \n",
    "                     X_train[:,1], \n",
    "                     c=y_train, \n",
    "                     cmap=cm_bright, \n",
    "                     edgecolors=\"k\",\n",
    "                     s=100*sample_weight\n",
    "                    )\n",
    "\n",
    "    if X_test is not None and y_test is not None:\n",
    "        disp.ax_.scatter(X_test[:,0], \n",
    "                         X_test[:,1], \n",
    "                         c=y_test, \n",
    "                         cmap=cm_bright, \n",
    "                         edgecolors=\"k\", \n",
    "                         marker='x',\n",
    "                         s=100\n",
    "                        )\n",
    "    disp.ax_.set_title('nombre estimateur: '+str(n_estimators))\n",
    "    plt.figure(figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faites varier le nombre d'estimateur utilisé entre 1 et 20 (en prenant une valeur sur 2) avec un arbre de décision de profondeur 1 pour l'estimateur de base et visualisez le changement dans la fonction apprise avec `plot_boundary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même question que précédemment mais utilisez un `Perceptron` avec les paramètres par défaut comme estimateur de base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Implémentation d'Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost (Adaptive Boosting) est une technique permettant d'améliorer les performances d'un algorithme de classification donné en prenant une somme pondérée intelligente de plusieurs instances du classificateur.\n",
    "\n",
    "Cette technique est basée sur la construction itérative d'une série de classifieurs tout en conservant un vecteur de poids indiquant la qualité de la classification de chaque point par les classifieurs précédents. À chaque étape, l'algorithme tente de construire un classifieur qui corrige les erreurs commises par les classifieurs précédents.\n",
    "\n",
    "En utilisant la notation suivante :\n",
    "\n",
    "- N - est la taille de l'ensemble de données.\n",
    "- $\\{x_{i},y_{i}\\}$ - Sont les features et les étiquettes entre {-1, 1}.\n",
    "\n",
    "les étapes de cet algorithme sont les suivantes :\n",
    "\n",
    "- Initialiser un vecteur de poids uniforme pour chaque point de données: $w^{(t=0)}_{i}=\\frac{1}{N}$\n",
    "- Itérer sur les étapes suivantes, avec un indice t, jusqu'à atteindre un certain critère d'arrêt :\n",
    "\n",
    "    1. Construire un classifieur optimal $h_{t}$ selon les données pondérées données $w^{t-1}_{i}$\n",
    "    2. Calculer l'erreur de prédiction de $h_{t}$ sur l'ensemble des données pondérées : $\\epsilon=\\dfrac{\\sum_{i}w^{t}_{i}\\mathbb{1}_{{h(x_{i}) \\neq y_{i}}}}{\\sum_{i}w^{t}_{i}}$.\n",
    "    3. Calculer le poids pour le classifieur $h_{t}$ selon : $\\alpha_{t}=\\gamma \\ln\\left(\\dfrac{1-\\epsilon}{\\epsilon}\\right)$ avec $\\gamma=\\frac{1}{2}$ par défaut.\n",
    "    4. Mettre à jour les poids des données selon $w^{t}_{i}=w^{t-1}_{i}\\exp\\left(-\\alpha_{t} y_{i} h(x_{i})\\right)$.\n",
    "    5. Normaliser le poids par $Z=\\sum_{i}w^{t}_{i}$ selon : $w^{t}_{i}=\\frac{w^{t}_{i}}{Z}$.\n",
    "\n",
    "\n",
    "\n",
    "- La prédiction finale sera alors la combinaison linéaire suivante des classifieurs entraînés : $h(x_{i})=\\text{sign}\\left(\\sum_{t}\\alpha_{t}h_{t}(x_{i})\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `init_sample` qui initialise un vecteur de taille $N$ de poids uniforme pour chaque point de données: $w^{(t=0)}_{i}=\\frac{1}{N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_sample(N):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ce bloc permet de valider votre code. Vous ne devez pas le modifier.  \n",
    "try:\n",
    "    np.testing.assert_equal(init_sample(100), np.ones(100)/100,\n",
    "                            err_msg=\"\\033[93m {}\\033[00m\" .format('Test 1 : Les valeurs de init_sample ne sont pas bien initialisées.'))\n",
    "except Exception as e: \n",
    "    print(\"\\033[91m {}\\033[00m\" .format('KO - Au moins un test n\\'est pas validé')) \n",
    "    print('Information sur le test non valide:')\n",
    "    print(e)\n",
    "    raise e\n",
    "else:\n",
    "    print(\"\\033[92m {}\\033[00m\" .format('Ok - Tous les tests sont validés.')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `copy_and_fit` qui va prendre en argument un estimator, un ensemble de données `{X,Y}` et les poids `sample_weight` ($w$ dans les formules précédentes) et qui retournera l'estimator apprit avec les `sample_weights`. Vous clonerez l'estimator avant de l'utiliser sur l'ensemble `{X,Y}` en utilisant librairie `copy`. Cette étape correspond à l'étape de construire d'un classifieur optimal $h_{t}$ selon les données pondérées données $w^{t-1}_{i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_fit(estimator, X, y, sample_weight):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `estimate_error` qui va prendre en argument un estimator, un ensemble de données `{X,Y}` et les `sample_weight`. Cette fonction va renvoyé l'erreur de classification qui correspond à l'étape de calcule de l'erreur de prédiction de $h_{t}$ sur l'ensemble des données pondérées : $\\epsilon=\\dfrac{\\sum_{i}w^{t}_{i}\\mathbb{1}_{{h(x_{i}) \\neq y_{i}}}}{\\sum_{i}w^{t}_{i}}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_error(estimator, X, y, sample_weight):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `compute_weight_classifier` qui prend en paramétres `classification_error` et $\\gamma$. Cette fonction calcule le poids $\\alpha_t$ pour le classifieur $h_{t}$ selon : $\\alpha_{t}=\\gamma \\ln\\left(\\dfrac{1-\\epsilon}{\\epsilon}\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_classifier(classification_error, gamma=0.5):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `update_sample_weight` qui prend en paramétres le poids pour le classifieur $h_{t}$ (`estimator_weight`), le poids des exemples (`sample_weight`) et les vecteurs y, y\\_predict. Cette fonction retourne la mise à jour les poids des données selon $w^{t}_{i}=w^{t-1}_{i}\\exp\\left(-\\alpha_{t} y_{i} h(x_{i}) \\right)$ et normalise les poids par $Z=\\sum_{i}w^{t}_{i}$ selon : $w^{t}_{i}=\\frac{w^{t}_{i}}{Z}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sample_weight(estimator_weight, sample_weight,y,y_predict):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Écrivez une fonction `predict` qui prendra `X` un ensemble de données, la liste des estimators `estimators_list` et enfin `estimators_weights` la liste des poids de chaque classifieurs. Cette fonction va prédire la prédiction finale qui sera alors la combinaison linéaire suivante des classifieurs entraînés : $h(x_{i})=\\text{sign}\\left(\\sum_{t}\\alpha_{t}h_{t}(x_{i})\\right)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(estimators_list, estimators_weights, X):\n",
    "    ### Your Code Here\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplissez la classe suivante avec les fonctions précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, estimator=None, n_estimators=50, learning_rate=0.5):\n",
    "        \"\"\"\n",
    "        estimator: L'estimateur de base à partir duquel l'ensemble boosté est construit.\n",
    "        n-estimators:(int) Le nombre maximum d'estimateurs pour lequel le boosting est terminé.\n",
    "        learning_rate: (float, default=1.0) Poids appliqué à chaque classificateur à chaque itération de boosting. \n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        #Begin Solution\n",
    "        self.estimator = estimator or DecisionTreeClassifier(max_depth=1) #Doit avoir Fit et Predict\n",
    "        #End Solution\n",
    "        self.sample_weight_list = []\n",
    "        self.estimators_list = []\n",
    "        self.estimator_weights_ = None\n",
    "        self.estimator_errors_ = None\n",
    "        self.transform = False\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # labels de type -1 / 1.\n",
    "        if np.any(y==0):\n",
    "            self.transform = True\n",
    "            y[y==0] = -1\n",
    "        else:\n",
    "            self.transform = False\n",
    "        \n",
    "        #Initialisation des poids des samples\n",
    "        ### Your Code Here\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        #Reset any provious Fit\n",
    "        self.sample_weight_list = []\n",
    "        self.sample_weight_list.append(sample_weight.copy())\n",
    "        self.estimators_list = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators, dtype=np.float64)\n",
    "        \n",
    "        for num_estimator in range(self.n_estimators):\n",
    "            # Boosting step\n",
    "            #Cloner et apprendre le current estimator\n",
    "            \n",
    "            ### Your Code Here\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            # Fraction d'erreur\n",
    "            ### Your Code Here\n",
    "            raise NotImplementedError()\n",
    "                        \n",
    "            if estimator_error <= 0:\n",
    "                estimator_weight = 1.0\n",
    "                estimator_error = 0.0\n",
    "                self.estimators_list.append(estimator)\n",
    "                self.estimator_weights_[num_estimator] = estimator_weight\n",
    "                self.estimator_errors_[num_estimator] = estimator_error\n",
    "                break\n",
    "\n",
    "            # Calcule du poids du classifieur\n",
    "            ### Your Code Here\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "            #Mise a jour des samples weight\n",
    "            ### Your Code Here\n",
    "            raise NotImplementedError()\n",
    "        \n",
    "            #Save Model, sample_weight, estimator_weights and estimator_errors\n",
    "            self.sample_weight_list.append(sample_weight)\n",
    "            self.estimators_list.append(estimator)\n",
    "            self.estimator_weights_[num_estimator] = estimator_weight\n",
    "            self.estimator_errors_[num_estimator] = estimator_error\n",
    "\n",
    "        if self.transform:\n",
    "            y[y==-1] = 0\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #Prediction\n",
    "        ### Your Code Here\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if self.transform:\n",
    "            predicted[predicted==-1] = 0 \n",
    "            \n",
    "        assert X.shape[0]==predicted.shape[0], \"X and predicted y must have the same size\"\n",
    "        return predicted\n",
    "        #end solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testez votre modèle en utilisant `make_circles` de `scikit-learn` (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html). Vous allez utiliser 500 samples, un bruit de 0.04 et un facteur de 0.3.\n",
    "\n",
    "Ensuite testez votre modèle en faisant varier le nombre d'estimateurs (utilisez la fonction plot_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your Code Here\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
