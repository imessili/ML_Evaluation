{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f83484c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ba140fed",
   "metadata": {},
   "source": [
    "La fonction f(x) est la fonction co√ªt (fonction objectif, crit√®re). Les\n",
    "fonctions gi x , gj x et gk x sont les contraintes. E est un ensemble\n",
    "sp√©cial appartenant √† Rn.\n",
    "\n",
    "\n",
    "Un point xa ‚àà Rn est solution admissible (feasible soution) de P si et\n",
    "seulement si : il respect les contrainte\n",
    "\n",
    "############################################\"\"\n",
    "\n",
    "Solution local\n",
    "\n",
    "‚Ä¢ Un point x\n",
    "\n",
    "‚àó ‚àà Rn est solution (optimum) local\n",
    "\n",
    "de P si et seulement si x\n",
    "\n",
    "‚àó est solution admissible\n",
    "\n",
    "et il existe un entourage (un disque) D(x\n",
    "‚àó\n",
    ", r)\n",
    "\n",
    "autour de x\n",
    "‚àó\n",
    "tel que f x\n",
    "\n",
    "‚àó ‚â§ f x ‚àÄx ‚àà D(x\n",
    "‚àó\n",
    ", r).\n",
    "\n",
    "Solution global\n",
    "\n",
    "‚Ä¢ Un point x\n",
    "\n",
    "‚àó est solution (optimum) globale\n",
    "\n",
    "de P si et seulement si : x\n",
    "\n",
    "‚àó est admissible\n",
    "\n",
    "et f x\n",
    "\n",
    "‚àó ‚â§ f xa ‚àÄ xa\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "Un point-selle (en anglais : saddle point)\n",
    "d'une fonction f d√©finie sur un produit\n",
    "cart√©sien X √ó Y de deux\n",
    "ensembles X et Y est un point x“ß, y‡¥§\n",
    "‚àà X √ó Y tel que :\n",
    "‚Ä¢ y ‚Üí f x“ß, y atteint un maximum en\n",
    "y‡¥§ sur Y ;\n",
    "‚Ä¢ Et x ‚Üí f x, y‡¥§ atteint un minimum\n",
    "en x“ßsur X.\n",
    "\n",
    "\n",
    "#######################################\n",
    "\n",
    "\n",
    "Un Ensemble E est convexe si et seulement si ‚àÄ x1et x2 ‚àà E il existe Œ±\n",
    "‚àà [0,1] tel que : Œ± x1 + 1 ‚àí Œ± x2 ‚àà E.\n",
    "\n",
    "\n",
    "######################################\n",
    "Une fonction est convexe Ssi l‚Äôensemble au-dessus de son graphe est\n",
    "convexe (Figure I-5 Fonction convexe)\n",
    "\n",
    "#####################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Partant de  (ùêó,ùê≤) , on cherche ainsi  ùê∞‚àà‚Ñùùëë tel que  ùêóùê∞‚àíùê≤‚âà0\n",
    "\n",
    "Sans a priori sur la nature du bruit dont les observations sont entach√©es (ou en supposant que ce bruit est gaussien), on peut formuler notre objectif comme un probl√®me aux moindres carr√©s :\n",
    "minimiserùê∞‚àà‚Ñùùëëùëì(ùê∞):=12ùëõ‚Äñùêóùê∞‚àíùê≤‚Äñ2=12ùëõ‚àëùëñ=1ùëõ(ùê±ùëáùëñùê∞‚àíùë¶ùëñ)2.\n",
    " \n",
    "Le probl√®me peut se r√©√©crire comme un probl√®me d'optimisation quadratique de la forme :\n",
    "minimiserùê∞‚àà‚Ñùùëë12ùê∞ùëáùêÄùê∞‚àíùêõùëáùê∞+ùëê.\n",
    " \n",
    "avec  ùêÄ=ùêóùëáùêóùëõ ,  ùêõ=ùêóùëáùê≤ùëõ et  ùëê=ùê≤ùëáùê≤2ùëõ.\n",
    "\n",
    "On a ainsi  ùëì(ùê∞)=12ùê∞ùëáùêÄùê∞‚àíùêõùëáùê∞+ùëê pour tout  ùê∞‚àà‚Ñùùëë .\n",
    "\n",
    "Cette fonction est de classe  ÓàØ1 (car polynomiale en chacune des variables), et son gradient est donn√© par ‚àáùëì(ùê∞)=ùêÄùê∞‚àíùêõ=1ùëõùêóùëá(ùêóùê∞‚àíùê≤).\n",
    " \n",
    "\n",
    "# Classe Python pour les probl√®mes de r√©gression lin√©aire\n",
    "class LinReg(object):\n",
    "    '''\n",
    "        Probl√®mes de r√©gression lin√©aire sous forme de moindres carr√©s lin√©aires.\n",
    "        \n",
    "        Attributs:\n",
    "            X: Tableau √† deux dimensions, matrice de donn√©es (caract√©ristiques)\n",
    "            y: Tableau √† une dimension, vecteur de donn√©es (labels/mesures/...)\n",
    "            n,d: Dimensions du probl√®me (X de taille n x d, y est de taille n)\n",
    "            \n",
    "        M√©thodes:\n",
    "            fun: Calcule la valeur de la fonction objectif pour les moindres carr√©s lin√©aires.\n",
    "            grad: Calcule la valeur du gradient pour les moindres carr√©s lin√©aires.\n",
    "            lipgrad: Calcule la valeur de la constante de Lipschitz pour le gradient.\n",
    "    '''     \n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n, self.d = X.shape\n",
    "    \n",
    "    # Fonction objectif\n",
    "    def fun(self, w):\n",
    "        ## COMPLETER LE CODE AVEC LA FORMULE DE LA FONCTION OBJECTIF\n",
    "        return (1/(2 * self.n)) * norm(X.dot(w) - y)**2\n",
    "    \n",
    "    # Gradient\n",
    "    def grad(self, w):\n",
    "        ## COMPLETER LE CODE AVEC LA FORMULE DU GRADIENT\n",
    "        return (1/n) * X.T.dot((X.dot(w)-y))\n",
    "\n",
    "    # Constante de Lipschitz pour le gradient\n",
    "    def lipgrad(self):\n",
    "        L = norm(self.X, ord=2) ** 2 / self.n # Calcul plus √©conome de ||X^T X||\n",
    "        return L \n",
    "\n",
    "## COMPLETER LE CODE AVEC L'INITIALIZATION DE LA CLASSE LinReg\n",
    "# G√©n√©ration de l'instance correspondante en utilisant la classe pr√©c√©dente\n",
    "pblinreg = LinReg(X ,y)\n",
    "\n",
    "# V√©rification des formules que vous avez impl√©ment√©, et de la coh√©rence entre la fonction et le gradient\n",
    "# important pour que l'algorithme fonctionne correctement\n",
    "# Si le code vous renvoie une valeur de l'ordre de 10^(-6), \n",
    "# √ßa veut dire que vous √™tes a priori bon, sinon rev√©rifier l'impl√©mention de fun et grad\n",
    "check_grad(pblinreg.fun, pblinreg.grad, np.random.randn(d))\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "L'algorithme de descente de gradient appliqu√© √† une fonction  ùëì\n",
    "  est d√©fini par un point initial  ùë§0\n",
    "  ainsi que par l'it√©ration\n",
    "ùê∞ùëò+1=ùê∞ùëò‚àíùõºùëò‚àáùëì(ùê∞ùëò),\n",
    " \n",
    "o√π  ùõºùëò>0\n",
    "  est une longueur de pas pour l'it√©ration  ùëò\n",
    " .\n",
    "\n",
    "############################################################################################\n",
    "# Descente de gradient\n",
    "def grad_desc(w0,problem, strategy=0,step0=1, n_iter=1000, verbose=False): \n",
    "    \"\"\"\n",
    "        Un code pour la descente de gradient sur probl√®mes structur√©s avec diff√©rents choix de \n",
    "        longueurs de pas.\n",
    "        \n",
    "        Entr√©es:\n",
    "            w0: Vecteur initial\n",
    "            problem: Structure repr√©sentant le probl√®me\n",
    "                problem.fun(w) Fonction objectif\n",
    "                problem.grad(w) Gradient\n",
    "                problem.lipgrad() Constante de Lipschitz du gradient\n",
    "            strategy: Strat√©gie pour la longueur de pas (see above)\n",
    "                \n",
    "                  \n",
    "            step0: Longueur de pas initial (utile pour la strategie d√©croissante)\n",
    "            n_iter: Nombre maximum d'it√©rations\n",
    "            verbose: Bool√©en r√©glant l'affichage des informations √† chaque it√©ration\n",
    "      \n",
    "        Sorties:\n",
    "            w_output: Les poids am√©lior√©s dans l'it√©r√© final de la m√©thode\n",
    "            objvals: Historique des valeurs de fonctions (tableau Numpy de taille n_iter) pour voir graphiquement l'√©volution  de la fonction objectif\n",
    "            ngvals: Historique des normes de gradient (tableau Numpy de taille n_iter) pour voir graphiquement la convergence de la strategie\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    ############\n",
    "    # Initialisation\n",
    "\n",
    "    # Historique des valeurs\n",
    "    objvals = []\n",
    "    # Normes de gradient\n",
    "    ngvals = []\n",
    "    \n",
    "    # Constante de Lipschitz\n",
    "    L = problem.lipgrad()\n",
    "    # Valeur initiale de l'it√©r√© courant   \n",
    "    w = w0.copy()\n",
    "\n",
    "    # Initialisation du compteur d'it√©rations\n",
    "    k=0    \n",
    "    \n",
    "    # Fonction objectif en le point courant\n",
    "    ## COMPLETER LE CODE AVEC LE CALCUL DE LA FONCTION OBJECTIF EN POINT INITIAL (POIDS INITIAUX) \n",
    "    \n",
    "    obj = problem.fun(w0)\n",
    "    \n",
    "    # Gradient en le point initial\n",
    "    ## COMPLETER LE CODE AVEC LE CALCUL DU GRADIENT EN POINT INITIAL\n",
    "\n",
    "    g = problem.grad(w0)\n",
    "    \n",
    "    # on garde une trace de la fonction objectif et la norme gradient pendant la recherche \n",
    "    objvals.append(obj);\n",
    "    ng = norm(g)\n",
    "    ngvals.append(ng)\n",
    "\n",
    "    # Affichage des valeurs initiales \n",
    "    if verbose:\n",
    "        print(\"Descente de gradient :\")\n",
    "        print(' | '.join([name.center(8) for name in [\"iter\", \"fval\", \"ngrad\"]]))\n",
    "        print(' | '.join([(\"%d\" % k).rjust(8),(\"%.2e\" % obj).rjust(8),(\"%.2e\" % ng).rjust(8)]))\n",
    "    \n",
    "    ####################\n",
    "    # Boucle principale\n",
    "    while (k < n_iter):\n",
    "        \n",
    "        # A COMPLETER AVEC LES DIFF√âRENTES STRAT√âGIES CIT√âES\n",
    "        # Choisir la longueur de pas et mettre √† jour l'it√©r√©\n",
    "        if strategy==0:\n",
    "            # Longueur de pas constante\n",
    "            w[:] = w - (step0 * g)\n",
    "        elif strategy==1:\n",
    "            # Longueur de pas decroissante\n",
    "            w[:] = w - ((step0/(k+1)) * g)\n",
    "        elif strategy==2:\n",
    "            # Longueur de pas decroissante a_0/(k+1)\n",
    "            w[:] = w - ((step0/np.sqrt(k+1)) * g)\n",
    "        elif strategy==3:\n",
    "            # Longueur de pas \n",
    "            w[:] = w - (1/L * g)\n",
    "        else:\n",
    "            print(\"no strategy was selected for the gradient\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # FIN A COMPLETER\n",
    "        \n",
    "        \n",
    "        # A COMPL√âTER AVEC LE CALCUL DE NOUVELLES INFORMATION EN POINT COURANT\n",
    "\n",
    "        obj = problem.fun(w)\n",
    "        g = problem.grad(w)\n",
    "\n",
    "        # on garde une trace de la fonction objectif et la norme gradient pendant la recherche \n",
    "        objvals.append(obj)\n",
    "        ng = norm(g)\n",
    "        ngvals.append(ng)\n",
    "        \n",
    "        # Affichage si demand√©\n",
    "        if verbose:\n",
    "            print(' | '.join([(\"%d\" % k).rjust(8),(\"%.2e\" % obj).rjust(8),(\"%.2e\" % ng).rjust(8)]))       \n",
    "        \n",
    "        # A COMPL√âTER POUVOIR PASSER √Ä L'IT√âRATION SUIVANTE\n",
    "        k += 1\n",
    "    \n",
    "    # Fin boucle principale\n",
    "    ######################\n",
    "    \n",
    "    # Informations de sortie\n",
    "    w_output = w.copy()\n",
    "    return w_output, np.array(objvals), np.array(ngvals)\n",
    "    \n",
    "###################################################################################\n",
    "\n",
    "\n",
    "# Tester quatre variantes de descente de gradient\n",
    "w0 = np.zeros(d)\n",
    "w_a, obj_a, ngrad_a = grad_desc(w0,pblinreg, strategy=0,step0=1/1.59, n_iter=100, verbose=False)\n",
    "w_b, obj_b, ngrad_b = grad_desc(w0,pblinreg, strategy=1,step0=1, n_iter=100, verbose=False)\n",
    "w_c, obj_c, ngrad_c = grad_desc(w0,pblinreg, strategy=2,step0=1, n_iter=100, verbose=False)\n",
    "w_d, obj_d, ngrad_d = grad_desc(w0,pblinreg, strategy=3,step0=1, n_iter=100, verbose=False)\n",
    "\n",
    "\n",
    "# Comparaison de trois variantes de descente de gradient \n",
    "\n",
    "# Affichage des meilleures valeurs obtenues\n",
    "print(\"Fonction objectif finale pour GD - 0.025\",obj_b[-1])\n",
    "print(\"Fonction objectif finale pour GD - 1/(k+1)\",obj_b[-1])\n",
    "print(\"Fonction objectif finale pour GD - 1/(sqrt(k+1))\",obj_c[-1])\n",
    "print(\"Fonction objectif finale pour GD - 1/L\",obj_a[-1])\n",
    "\n",
    "print(pblinreg.lipgrad())\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "# Note : en √©chelle logarithmique, les valeurs f(w)-vmin tr√®s proches de 0 ne s'affichent pas\n",
    "# on calcule le vmin sur la formule originale des moindres carr√©s \n",
    "vmin = (1/(2*n))*(norm(X.dot(np.linalg.pinv(X).dot(y))-y)**2)\n",
    "# Pour ne pas afficher d'√©cart relatif, on prendra vmin √©gal √† 0 (le minorant de la question 1)\n",
    "# vmin = 0\n",
    "\n",
    "# En termes de fonction objectif \n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.semilogy(np.trim_zeros(obj_a-vmin), label=\"GD - 0.025\", lw=2)\n",
    "plt.semilogy(np.trim_zeros(obj_b-vmin), label=\"GD - 1/(k+1)\", lw=2)\n",
    "plt.semilogy(np.trim_zeros(obj_c-vmin), label=\"GD - 1/(sqrt(k+1))\", lw=2)\n",
    "plt.semilogy(np.trim_zeros(obj_d-vmin), label=\"GD - 1/L\", lw=2)\n",
    "plt.title(\"Convergence\", fontsize=16)\n",
    "plt.xlabel(\"#it√©rations\", fontsize=14)\n",
    "plt.ylabel(\"Objectif - Meilleure valeur(log)\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.savefig('foo.pdf')\n",
    "\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# En termes de norme de gradient\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.semilogy(ngrad_a, label=\"GD - 0.025\", lw=2)\n",
    "plt.semilogy(ngrad_b, label=\"GD - 1/L\", lw=2)\n",
    "plt.semilogy(ngrad_c , label=\"GD - 1/(k+1)\", lw=2)\n",
    "plt.semilogy(ngrad_d, label=\"GD - 1/(sqrt(k+1))\", lw=2)\n",
    "plt.title(\"Convergence\", fontsize=16)\n",
    "plt.xlabel(\"#it√©rations\", fontsize=14)\n",
    "plt.ylabel(\"Norme du gradient (log)\", fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "#######################################################################################\n",
    "\n",
    "# Classe Python pour les probl√®mes quadratiques homog√®nes\n",
    "class QuadPb(object):\n",
    "    '''\n",
    "        Classe de probl√®mes de la forme minimiser_w 0.5*w^T A w, avec A une matrice sym√©trique.\n",
    "        \n",
    "        Attributs:\n",
    "            A: Matrice carr√©e sym√©trique\n",
    "            d: Nombre de lignes/Nombre de colonnes de la matrice\n",
    "            \n",
    "        M√©thodes:\n",
    "            fun: Calcul de la valeur de l'objectif 0.5*w^T A w en w\n",
    "            grad: Calcul du gradient de l'objectif A w en w\n",
    "            lipgrad: Calcul de la constante de Lipschitz ||A|| pour le gradient\n",
    "    '''\n",
    "   \n",
    "    # Constructeur\n",
    "    def __init__(self, A):\n",
    "        self.A = A\n",
    "        self.d = A.shape[0]\n",
    "    \n",
    "    # Fonction objectif\n",
    "    def fun(self, w):\n",
    "        ## COMPLETER LE CODE AVEC LA FORMULE DE LA FONCTION OBJECTIF\n",
    "        return (1/(2 * self.n)) * norm(X.dot(w) - y)**2\n",
    "    \n",
    "    # Calcul du gradient\n",
    "    def grad(self, w):\n",
    "        ## COMPLETER LE CODE AVEC LA FORMULE DU GRADIENT\n",
    "        return (1/n) * X.T.dot((X.dot(w)-y))\n",
    "\n",
    "    # Constante de Lipschitz pour le gradient\n",
    "    def lipgrad(self):\n",
    "        L = norm(self.X, ord=2) ** 2 / self.n # Calcul plus √©conome de ||X^T X||\n",
    "        return L \n",
    "        \n",
    "#####################################################################################\n",
    "\n",
    "# Descente de gradient\n",
    "def grad_desc(w0,problem,stepchoice=0,step0=1, n_iter=1000, verbose=False): \n",
    "    \"\"\"\n",
    "        Un code pour la descente de gradient sur probl√®mes structur√©s avec diff√©rents choix de \n",
    "        longueurs de pas.\n",
    "        \n",
    "        Entr√©es:\n",
    "            w0: Vecteur initial\n",
    "            problem: Structure repr√©sentant le probl√®me\n",
    "                problem.fun(w) Fonction objectif\n",
    "                problem.grad(w) Gradient\n",
    "                problem.lipgrad() Constante de Lipschitz du gradient\n",
    "            stepchoice: Strat√©gie pour la longueur de pas (see above)\n",
    "                0: Constante √©gale √† 1/L\n",
    "            step0: Longueur de pas initiale (utile si stepchoice = 1)\n",
    "            n_iter: Nombre maximum d'it√©rations\n",
    "            verbose: Bool√©en r√©glant l'affichage des informations √† chaque it√©ration\n",
    "      \n",
    "        Sorties:\n",
    "            w_output: It√©r√© final de la m√©thode\n",
    "            objvals: Historique des valeurs de fonctions (tableau Numpy de taille n_iter)\n",
    "            ngvals: Historique des normes de gradient (tableau Numpy de taille n_iter)\n",
    "            \n",
    "    \"\"\"\n",
    "    ############\n",
    "    # Initialisation\n",
    "\n",
    "    # Historique des valeurs\n",
    "    objvals = []\n",
    "    # Normes de gradient\n",
    "    ngvals = []\n",
    "    \n",
    "    # Constante de Lipschitz\n",
    "    L = problem.lipgrad()\n",
    "    # Valeur initiale de l'it√©r√© courant   \n",
    "    w = w0.copy()\n",
    "\n",
    "    # Initialisation du compteur d'it√©rations\n",
    "    k=0    \n",
    "    \n",
    "    # Fonction objectif en le point courant\n",
    "    ## COMPLETER LE CODE AVEC LE CALCUL DE LA FONCTION OBJECTIF EN POINT INITIAL (POIDS INITIAUX) \n",
    "    \n",
    "    obj = problem.fun(w0)\n",
    "    \n",
    "    # Gradient en le point initial\n",
    "    ## COMPLETER LE CODE AVEC LE CALCUL DU GRADIENT EN POINT INITIAL\n",
    "\n",
    "    g = problem.grad(w0)\n",
    "    \n",
    "    # on garde une trace de la fonction objectif et la norme gradient pendant la recherche \n",
    "    objvals.append(obj);\n",
    "    ng = norm(g)\n",
    "    ngvals.append(ng)\n",
    "\n",
    "    # Affichage des valeurs initiales \n",
    "    if verbose:\n",
    "        print(\"Descente de gradient :\")\n",
    "        print(' | '.join([name.center(8) for name in [\"iter\", \"fval\", \"ngrad\"]]))\n",
    "        print(' | '.join([(\"%d\" % k).rjust(8),(\"%.2e\" % obj).rjust(8),(\"%.2e\" % ng).rjust(8)]))\n",
    "    \n",
    "    ####################\n",
    "    # Boucle principale\n",
    "    while (k < n_iter):\n",
    "        \n",
    "        # A COMPLETER AVEC LES DIFF√âRENTES STRAT√âGIES CIT√âES\n",
    "        # Choisir la longueur de pas et mettre √† jour l'it√©r√©\n",
    "        if strategy==0:\n",
    "            # Longueur de pas \n",
    "            w[:] = w - (1/L * g)\n",
    "        else:\n",
    "            print(\"no strategy was selected for the gradient\")\n",
    "            sys.exit(1)\n",
    "        \n",
    "        # FIN A COMPLETER\n",
    "        \n",
    "        \n",
    "        # A COMPL√âTER AVEC LE CALCUL DE NOUVELLES INFORMATION EN POINT COURANT\n",
    "\n",
    "        obj = problem.fun(w)\n",
    "        g = problem.grad(w)\n",
    "\n",
    "        # on garde une trace de la fonction objectif et la norme gradient pendant la recherche \n",
    "        objvals.append(obj)\n",
    "        ng = norm(g)\n",
    "        ngvals.append(ng)\n",
    "        \n",
    "        # Affichage si demand√©\n",
    "        if verbose:\n",
    "            print(' | '.join([(\"%d\" % k).rjust(8),(\"%.2e\" % obj).rjust(8),(\"%.2e\" % ng).rjust(8)]))       \n",
    "        \n",
    "        # A COMPL√âTER POUVOIR PASSER √Ä L'IT√âRATION SUIVANTE\n",
    "        k += 1\n",
    "    \n",
    "    # Fin boucle principale\n",
    "    ######################\n",
    "    \n",
    "    \n",
    "    return w_output, np.array(objvals), np.array(ngvals)\n",
    "    \n",
    "#########################################################################################################\n",
    "\n",
    "# Creation de l'instance de classe QuadPb\n",
    "pbquad = QuadPb(A)\n",
    "# Tester un ensemble de points initiaux au hasard\n",
    "ntrials = 30\n",
    "step = 1\n",
    "\n",
    "# Bool√©en pour l'ajout d'un point probl√©matique\n",
    "#failpt = False\n",
    "failpt = True\n",
    "\n",
    "# Initialisation de structures\n",
    "if failpt:\n",
    "    W0 = np.zeros((ntrials+1,d))\n",
    "    Wf = np.zeros((ntrials+1,d))\n",
    "    vf = np.zeros(ntrials+1)\n",
    "else:\n",
    "    W0 = np.zeros((ntrials,d))\n",
    "    Wf = np.zeros((ntrials,d))\n",
    "    vf = np.zeros(ntrials)\n",
    "\n",
    "# Compteur du nombre de bonnes ex√©cutions (pour lesquelles on esquive l'origine)\n",
    "goodtrials = 0\n",
    "\n",
    "# Lancement des instances de l'algorithme\n",
    "for i in range(ntrials):\n",
    "    w0 = uniform([-1,-1],[1,1],size=d)\n",
    "    W0[i,:] = w0 \n",
    "    Wf[i,:], obj_q, ngrad_q = grad_desc(w0,pbquad,0,step,100)\n",
    "    vf[i] = obj_q[-1]\n",
    "    if vf[i]<0:\n",
    "        goodtrials += 1\n",
    "        \n",
    "# Ajout d'un point probl√©matique pour la descente de gradient\n",
    "if failpt:\n",
    "    # A COMPLETER\n",
    "    w0 = np.ones(d)\n",
    "    w0[-1] = 0 # Pas de composante selon les vecteurs propres correspondant aux valeurs propres n√©gatives\n",
    "    W0[ntrials,:] = w0\n",
    "    # FIN A COMPLETER\n",
    "    Wf[ntrials,:], obj_q, ngrad_q = grad_desc(w0,pbquad,0,step,100)\n",
    "    vf[ntrials] = obj_q[-1]\n",
    "    if vf[ntrials]<0:\n",
    "        goodtrials +=1\n",
    "\n",
    "if failpt:\n",
    "    print('La descente de gradient esquive le point selle ',goodtrials,' fois sur ', ntrials+1)\n",
    "else:\n",
    "    print('La descente de gradient esquive le point selle ',goodtrials,' fois sur ', ntrials)\n",
    "    \n",
    "# Affichage des resultats (uniquement en dimension 2)\n",
    "if d==2:\n",
    "    npts = vf.size\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.contour(w1,w2,fw,levels=30)\n",
    "    plt.colorbar()\n",
    "    for i in range(npts):\n",
    "        plt.plot(W0[i,0],Wf[i,1],'o',color='blue')\n",
    "        if vf[i]<0:\n",
    "            plt.plot(Wf[i,0],Wf[i,1],'o',color='green')\n",
    "        else:\n",
    "            plt.plot(Wf[i,0],Wf[i,1],'o',color='red')\n",
    "            \n",
    "            \n",
    "##################################################################################\n",
    "\n",
    "\n",
    "D√©finitions Cl√©s\n",
    "Optimisation: Processus de maximisation ou de minimisation d'une fonction objectif dans le but de trouver la meilleure solution possible parmi un ensemble de solutions possibles.\n",
    "Variable de d√©cision: Les √©l√©ments ou param√®tres que l'on peut contr√¥ler ou ajuster dans un probl√®me d'optimisation.\n",
    "Fonction objectif: La fonction que l'on cherche √† maximiser ou √† minimiser. Elle mesure la performance ou l'efficacit√© d'une d√©cision.\n",
    "Ensemble de contraintes: Les restrictions ou limites impos√©es aux variables de d√©cision.\n",
    "Processus d'Optimisation\n",
    "Mod√©lisation: Conversion d'un probl√®me r√©el en un mod√®le math√©matique.\n",
    "R√©solution: Utilisation d'algorithmes pour trouver la solution optimale.\n",
    "Interpr√©tation: Analyse et validation des r√©sultats avec des experts du domaine.\n",
    "Types d'Optimisation\n",
    "Optimisation continue vs. discr√®te: D√©pend si les variables de d√©cision peuvent prendre n'importe quelle valeur dans un intervalle ou si elles sont limit√©es √† des valeurs sp√©cifiques.\n",
    "Optimisation sans contraintes vs. sous contraintes: Si le probl√®me permet ou non des valeurs libres de variables ou s'il est limit√© par des contraintes.\n",
    "Optimisation locale vs. globale: Cherche soit un optimum local soit un optimum global.\n",
    "Optimisation stochastique vs. d√©terministe: Si le mod√®le incorpore de l'incertitude (stochastique) ou non (d√©terministe).\n",
    "M√©thodes d'Optimisation\n",
    "Descente de gradient: M√©thode pour trouver le minimum d'une fonction en se d√©pla√ßant dans la direction oppos√©e au gradient de la fonction.\n",
    "Concepts et Th√©orie Pr√©sent√©s\n",
    "Types d'Optimisation :\n",
    "Optimisation Dynamique : Recherche d'une fonction sur un ensemble de points maximisant ou minimisant un objectif donn√©, souvent appel√©e optimisation √† dimension infinie. Elle est utilis√©e en automatique sous le nom de commande optimale.\n",
    "Optimisation Statique : Recherche d'un point dans ‚Ñù^n qui maximise ou minimise une fonction objective. Ce type est aussi d√©sign√© sous le nom de programmation math√©matique √† dimension finie.\n",
    "Formulation de Probl√®mes d'Optimisation :\n",
    "Un probl√®me typique d'optimisation est exprim√© en minimisant une fonction objective ùëì(ùë•)f(x) sous des contraintes d√©finies par des in√©galit√©s ou √©galit√©s sur les variables de d√©cision.\n",
    "Types de Programmes :\n",
    "Programme Lin√©aire : Toutes les fonctions (objectif et contraintes) sont lin√©aires.\n",
    "Programme √† Variables Enti√®res : Variables de d√©cision dans l'ensemble des entiers.\n",
    "Programme Non Lin√©aire Continu : Fonctions objectif et contraintes non lin√©aires.\n",
    "Solutions d'Optimisation :\n",
    "Solution Admissible : Point qui respecte toutes les contraintes du probl√®me.\n",
    "Solution Locale : Meilleure solution dans un voisinage imm√©diat du point.\n",
    "Solution Globale : Meilleure solution sur tout l'ensemble admissible.\n",
    "Th√©orie Convexe :\n",
    "Analyse Convexe : Important en optimisation car elle garantit que tout optimum local est un optimum global sous conditions de convexit√©.\n",
    "Fonctions Convexes : Fonction o√π la ligne reliant deux points sur le graphe est toujours au-dessus du graphe entre ces points.\n",
    "Matrice Hessienne : Pour qu'une fonction soit convexe, sa matrice Hessienne doit √™tre semi-d√©finie positive.\n",
    "Gradient et Matrice Hessienne :\n",
    "Gradient : Vecteur des d√©riv√©es partielles indiquant la direction de la plus grande augmentation de la fonction.\n",
    "Matrice Hessienne : Matrice des secondes d√©riv√©es partielles utilis√©e pour √©tudier la convexit√© et les points de selle de la fonction.\n",
    "\n",
    "\n",
    "##############################################\n",
    "\n",
    "Question 1\n",
    "Q: Expliquez ce qu'est une \"fonction objectif\" dans un probl√®me d'optimisation et donnez un exemple simple.\n",
    "\n",
    "R: Une fonction objectif est une fonction math√©matique que l'on cherche √† maximiser ou √† minimiser dans le cadre d'un probl√®me d'optimisation. Par exemple, dans un probl√®me de minimisation des co√ªts, la fonction objectif pourrait √™tre le co√ªt total des op√©rations, que l'on cherche √† r√©duire.\n",
    "\n",
    "Question 2\n",
    "Q: D√©crivez la diff√©rence entre l'optimisation sans contraintes et l'optimisation sous contraintes.\n",
    "\n",
    "R: L'optimisation sans contraintes cherche le minimum ou le maximum d'une fonction sur l'ensemble de son domaine sans restrictions suppl√©mentaires. L'optimisation sous contraintes, en revanche, cherche √† optimiser une fonction objectif tout en satisfaisant des contraintes qui limitent les valeurs admissibles des variables de d√©cision.\n",
    "\n",
    "Question 3\n",
    "Q: Qu'est-ce qu'une solution admissible dans un probl√®me d'optimisation sous contraintes? Donnez un exemple.\n",
    "\n",
    "R: Une solution admissible est une solution qui respecte toutes les contraintes du probl√®me d'optimisation. Par exemple, si un probl√®me contraint une variable \n",
    "ùë•\n",
    "x √† √™tre sup√©rieure √† 10, alors toute valeur de \n",
    "ùë•\n",
    "x √©gale ou sup√©rieure √† 10 est admissible.\n",
    "\n",
    "Question 4\n",
    "Q: Expliquez ce que signifie une solution optimale locale et globale dans le contexte de l'optimisation.\n",
    "\n",
    "R: Une solution optimale locale est une solution qui est la meilleure (minimale ou maximale) dans un voisinage local autour de cette solution. Une solution optimale globale est la meilleure solution parmi toutes les solutions admissibles sur l'ensemble du domaine du probl√®me.\n",
    "\n",
    "Question 5\n",
    "Q: Qu'est-ce qu'un point de selle dans un contexte math√©matique et comment cela se rapporte-t-il √† l'optimisation?\n",
    "\n",
    "R: Un point de selle est un point qui est un minimum le long d'une direction et un maximum le long d'une autre direction dans un espace multidimensionnel. En optimisation, cela indique un point o√π la fonction n'est ni purement maximis√©e ni purement minimis√©e, ce qui peut √™tre crucial dans l'identification de solutions stables ou d'√©quilibre.\n",
    "\n",
    "Question 6\n",
    "Q: Comment la notion de convexit√© affecte-t-elle la r√©solution des probl√®mes d'optimisation?\n",
    "\n",
    "R: La convexit√© est une propri√©t√© cl√© qui simplifie la r√©solution des probl√®mes d'optimisation, car elle garantit que tout minimum local est √©galement un minimum global. Cela permet aux algorithmes d'optimisation de trouver efficacement la solution optimale sans risquer de rester bloqu√©s dans des minima locaux non optimaux."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
